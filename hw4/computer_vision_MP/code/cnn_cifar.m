% function are called with two types
% either cnn_cifar('coarse') or cnn_cifar('fine')
% coarse will classify the image into 20 catagories
% fine will classify the image into 100 catagories
function cnn_cifar(type, varargin)

if ~(strcmp(type, 'fine') || strcmp(type, 'coarse'))
    error('The argument has to be either fine or coarse');
end

% record the time
tic
%% --------------------------------------------------------------------
%                                                         Set parameters
% --------------------------------------------------------------------
%
% data directory
opts.dataDir = fullfile('cifar_data','cifar') ;
% experiment result directory
opts.expDir = fullfile('cifar_data','cifar-baseline') ;
% image database
opts.imdbPath = fullfile(opts.expDir, 'imdb.mat');
% set up the batch size (split the data into batches)
opts.train.batchSize = 100 ;
% number of Epoch (iterations)
opts.train.numEpochs = 25 ;
% resume the train
opts.train.continue = true ;
% use the GPU to train
opts.train.useGpu = false ;
% set the learning rate
opts.train.learningRate = [0.001*ones(1, 10) 0.0001*ones(1,15)] ;
% set weight decay
opts.train.weightDecay = 0.0005 ;
% set momentum
opts.train.momentum = 0.9 ;
% experiment result directory
opts.train.expDir = opts.expDir ;
% parse the varargin to opts.
% If varargin is empty, opts argument will be set as above
opts = vl_argparse(opts, varargin);

% --------------------------------------------------------------------
%                                                         Prepare data
% --------------------------------------------------------------------

imdb = load(opts.imdbPath) ;


%% Define network
% The part you have to modify
net.layers = {} ;

k = 30;

% --------------------------------------------------------------------
%                                n = 1
% --------------------------------------------------------------------
nk = 1*k;

dropout_rate = 0.0;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 3; % c3 for only the first one
net.layers{end+1} = struct(...
    'name', '300c3', ...
    'type', 'conv', ...                        % RGB: 3 channels
    'filters', 0.0001 * randn(filter_size,filter_size,3,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ...
    'pad', 32, ... % note that only the first one gets padding
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;

net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

net.layers{end+1} = struct(...
    'type', 'pool', ...
    'method', 'max', ...
    'pool', [2 2], ...
    'stride', 2, ...
    'pad', 0) ; % MP2

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,nk,nk,'single'), ...
%     'biases', zeros(1,nk,'single'), ...
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                n = 2
% --------------------------------------------------------------------
n_1k = nk;
nk = 2*k;

dropout_rate = 0.0;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 2;
net.layers{end+1} = struct(...
    'name', '2*300c2', ...
    'type', 'conv', ...
    'filters', 0.0001 * randn(filter_size,filter_size,n_1k,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ...
    'pad', 0, ...
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;


net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

net.layers{end+1} = struct(...
    'type', 'pool', ...
    'method', 'max', ...
    'pool', [2 2], ...
    'stride', 2, ...
    'pad', 0) ; % MP2

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '2*300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,nk,nk,'single'), ...
%     'biases', zeros(1,nk,'single'), ...
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                n = 3
% --------------------------------------------------------------------
n_1k = nk;
nk = 3*k;

dropout_rate = 0.1;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 2;
net.layers{end+1} = struct(...
    'name', '3*300c2', ...
    'type', 'conv', ...
    'filters', 0.0001 * randn(filter_size,filter_size,n_1k,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ...
    'pad', 0, ...
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;


net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

net.layers{end+1} = struct(...
    'type', 'pool', ...
    'method', 'max', ...
    'pool', [2 2], ...
    'stride', 2, ...
    'pad', 0) ; % MP2

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '3*300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,nk,nk,'single'), ...
%     'biases', zeros(1,nk,'single'), ...
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                n = 4
% --------------------------------------------------------------------
n_1k = nk;
nk = 4*k;

dropout_rate = 0.2;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 2;
net.layers{end+1} = struct(...
    'name', '4*300c2', ...
    'type', 'conv', ...
    'filters', 0.0001 * randn(filter_size,filter_size,n_1k,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ...
    'pad', 0, ...
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;


net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

net.layers{end+1} = struct(...
    'type', 'pool', ...
    'method', 'max', ...
    'pool', [2 2], ...
    'stride', 2, ...
    'pad', 0) ; % MP2

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '4*300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,nk,nk,'single'), ...
%     'biases', zeros(1,nk,'single'), ...
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                n = 5
% --------------------------------------------------------------------
n_1k = nk;
nk = 5*k;

dropout_rate = 0.3;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 2;
net.layers{end+1} = struct(...
    'name', '5*300c2', ...
    'type', 'conv', ...
    'filters', 0.0001 * randn(filter_size,filter_size,n_1k,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ...
    'pad', 0, ...
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;


net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

net.layers{end+1} = struct(...
    'type', 'pool', ...
    'method', 'max', ...
    'pool', [2 2], ...
    'stride', 2, ...
    'pad', 0) ; % MP2

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '5*300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,nk,nk,'single'), ...
%     'biases', zeros(1,nk,'single'), ...
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                n = 6
% --------------------------------------------------------------------
n_1k = nk;
nk = 100; % 6*k; TODO 100 for 'fine'?

dropout_rate = 0.4;
net.layers{end+1} = struct(...
  'type', 'dropout', ...
  'rate', dropout_rate) ; % dropout

filter_size = 2;
net.layers{end+1} = struct(...
    'name', '6*300c2', ...
    'type', 'conv', ...
    'filters', 0.0001 * randn(filter_size,filter_size,n_1k,nk,'single'), ...
    'biases', zeros(1,nk,'single'), ... %
    'pad', 0, ...
    'stride', 1) ;

net.layers{end+1} = struct(...
    'type', 'bnorm', ...
    'weights', {{ones(1, nk, 'single'), zeros(1, nk, 'single'), zeros(2, nk, 'single')}}) ;

% No MP2 for last level

net.layers{end+1} = struct(...
  'type', 'relu') ; % ReLu

% filter_size = 1;
% net.layers{end+1} = struct(...
%     'name', '300c1', ...
%     'type', 'conv', ...
%     'filters', 0.0001 * randn(filter_size,filter_size,100,100,'single'), ...
%     'biases', zeros(1,100,'single'), ... % TODO 100 for 'fine'?
%     'pad', 0, ...
%     'stride', 1) ; % NiN layer
%
% net.layers{end+1} = struct(...
%   'type', 'relu', ...
%   'leak', 1/3) ; % leaky ReLu

% --------------------------------------------------------------------
%                                output
% --------------------------------------------------------------------
% dropout_rate = 0.5;
% net.layers{end+1} = struct(...
%   'type', 'dropout', ...
%   'rate', dropout_rate) ; % dropout
net.layers{end+1} = struct('type', 'softmaxloss') ;
%net.layers{end+1} = struct('type', 'softmax') ; % softmax


% % 1 conv1
% net.layers{end+1} = struct('type', 'conv', ...
%   'filters', 1e-4*randn(5,5,3,32, 'single'), ...
%   'biases', zeros(1, 32, 'single'), ...
%   'filtersLearningRate', 1, ...
%   'biasesLearningRate', 2, ...
%   'stride', 1, ...
%   'pad', 2) ;
%
% % 2 pool1 (max pool)
% net.layers{end+1} = struct('type', 'pool', ...
%                            'method', 'max', ...
%                            'pool', [5 5], ...
%                            'stride', 2, ...
%                            'pad', [0 1 0 1]) ;
%
% % 3 conv2
% net.layers{end+1} = struct('type', 'conv', ...
%   'filters', 0.01*randn(7,7,32,32, 'single'),...
%   'biases', zeros(1,32,'single'), ...
%   'filtersLearningRate', 1, ...
%   'biasesLearningRate', 2, ...
%   'stride', 1, ...
%   'pad', 0) ;
%
% % 4 relu2
% net.layers{end+1} = struct('type', 'relu') ;
%
% % 5 pool2 (avg pool)
% net.layers{end+1} = struct('type', 'pool', ...
%                            'method', 'avg', ...
%                            'pool', [7 7], ...
%                            'stride', 2, ...
%                            'pad', [0 1 0 1]) ;
%
% % 6 conv5
% net.layers{end+1} = struct('type', 'conv', ...
%                            'filters', 0.1*randn(2,2,32,100, 'single'),...
%                            'biases', zeros(1,100,'single'), ...
%                            'filtersLearningRate', 1, ...
%                            'biasesLearningRate', 2, ...
%                            'stride', 1, ...
%                            'pad', 0) ;
% % 7 loss
% net.layers{end+1} = struct('type', 'softmaxloss') ;


% --------------------------------------------------------------------
%                                                                Train
% --------------------------------------------------------------------

% Take the mean out and make GPU if needed
imdb.images.data = bsxfun(@minus, imdb.images.data, mean(imdb.images.data,4)) ;
if opts.train.useGpu
  imdb.images.data = gpuArray(imdb.images.data) ;
end
%% display the net
vl_simplenn_display(net);
%% start training
[net,info] = cnn_train_cifar(net, imdb, @getBatch, ...
    opts.train, ...
    'val', find(imdb.images.set == 2) , 'test', find(imdb.images.set == 3)) ;
%% Record the result into csv and draw confusion matrix
load(['cifar_data/cifar-baseline/net-epoch-' int2str(opts.train.numEpochs) '.mat']);
load(['cifar_data/cifar-baseline/imdb' '.mat']);
fid = fopen('cifar_prediction.csv', 'w');
strings = {'ID','Label'};
for row = 1:size(strings,1)
    fprintf(fid, repmat('%s,',1,size(strings,2)-1), strings{row,1:end-1});
    fprintf(fid, '%s\n', strings{row,end});
end
fclose(fid);
ID = 1:numel(info.test.prediction_class);
dlmwrite('cifar_prediction.csv',[ID', info.test.prediction_class], '-append');

val_groundtruth = images.labels(45001:end);
val_prediction = info.val.prediction_class;
val_confusionMatrix = confusion_matrix(val_groundtruth , val_prediction);
cmp = jet(50);
figure ;
imshow(ind2rgb(uint8(val_confusionMatrix),cmp));
imwrite(ind2rgb(uint8(val_confusionMatrix),cmp) , 'cifar_confusion_matrix.png');
toc

% --------------------------------------------------------------------
%% call back function get the part of the batch
function [im, labels] = getBatch(imdb, batch , set)
% --------------------------------------------------------------------
im = imdb.images.data(:,:,:,batch) ;
% data augmentation
if set == 1 % training
    % fliplr

    % noise

    % random crop

    % and other data augmentation
end


if set ~= 3
    labels = imdb.images.labels(1,batch) ;
end
